{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Unitree G1 Robot Training with Mujoco (Colab-Compatible)\n",
    "\n",
    "This notebook trains a locomotion policy for the Unitree G1 humanoid robot using:\n",
    "- **Mujoco** physics simulation (CPU/GPU compatible, works on Colab)\n",
    "- **PPO** reinforcement learning algorithm (rsl_rl)\n",
    "- **No Isaac Gym required** - runs entirely on Google Colab free tier\n",
    "\n",
    "After training, you can download the policy and visualize it locally with Mujoco.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Runtime**: Go to `Runtime > Change runtime type` and select `GPU` (T4 recommended)\n",
    "2. **Run all cells** in order\n",
    "3. **Training time**: ~13 hours for 10,000 iterations (can stop earlier and resume later)\n",
    "4. **Download trained models** at the end\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-deps"
   },
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install required packages for Mujoco-based training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q mujoco==3.2.3\n",
    "!pip install -q scipy\n",
    "!pip install -q pyyaml\n",
    "!pip install -q tensorboard\n",
    "!pip install -q rsl-rl-lib\n",
    "!pip install -q matplotlib\n",
    "!pip install -q numpy\n",
    "\n",
    "print(\"\\nâœ… Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## 2. Clone Repository and Install Package\n",
    "\n",
    "Clone the modified unitree_rl_mugym repository with Mujoco support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Remove old clone if exists\n",
    "if os.path.exists('unitree_rl_mugym'):\n",
    "    !rm -rf unitree_rl_mugym\n",
    "    print(\"Removed old repository\")\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/julienokumu/unitree_rl_mugym.git\n",
    "print(\"\\nâœ… Repository cloned!\")\n",
    "\n",
    "# Change to repo directory\n",
    "%cd unitree_rl_mugym\n",
    "\n",
    "# Install package (without Isaac Gym dependencies)\n",
    "!pip install -q -e . --no-deps\n",
    "\n",
    "print(\"\\nâœ… Package installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "verify"
   },
   "source": [
    "## 3. Verify Installation\n",
    "\n",
    "Check that Mujoco and the package are properly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-code"
   },
   "outputs": [],
   "source": [
    "import mujoco\n",
    "import torch\n",
    "from legged_gym.envs.g1.mujoco_g1_env import MujocoG1Robot\n",
    "from legged_gym.envs.g1.mujoco_g1_config import MujocoG1RoughCfg, MujocoG1RoughCfgPPO\n",
    "\n",
    "print(\"âœ… All imports successful!\")\n",
    "print(f\"Mujoco version: {mujoco.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": "## 4. Start Training\n\nTrain the G1 locomotion policy using PPO with Mujoco simulation.\n\n**Training Parameters:**\n- **Environments**: 512 parallel simulations\n- **Device**: CUDA (GPU)\n- **Max iterations**: 1000 (adjustable - see options below)\n- **Save interval**: Every 50 iterations\n- **Expected time**: ~2 hours for 50 iterations, ~3.5 hours for 100 iterations\n\n**Training Options:**\n- **Quick test** (5 iterations): ~10 minutes - verify everything works\n- **Short session** (50 iterations): ~2 hours - fits Colab free tier nicely\n- **Medium session** (100 iterations): ~3.5 hours - good progress\n- **Full training** (1000 iterations): ~35 hours - requires multiple resume sessions\n\n**Notes:**\n- Colab free tier provides 12-hour sessions - plan accordingly\n- Models are automatically saved every 50 iterations\n- You can interrupt training anytime (Ctrl+C or stop button)\n- Resume training later from any checkpoint\n- Monitor progress in real-time with TensorBoard (next cell)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-code"
   },
   "outputs": [],
   "source": "# Start training with Mujoco\n# Default: 1000 iterations (~35 hours total, save every 50)\n# For 2-hour session: Use --max_iterations 50\n# For quick test: Use --max_iterations 5\n!python legged_gym/scripts/train_mujoco.py \\\n    --device cuda \\\n    --num_envs 512 \\\n    --max_iterations 50\n\nprint(\"\\nâœ… Training completed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor"
   },
   "source": [
    "## 5. Monitor Training Progress (Optional)\n",
    "\n",
    "Launch TensorBoard to visualize training metrics in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard"
   },
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Launch TensorBoard\n",
    "%tensorboard --logdir logs/g1_colab_training\n",
    "\n",
    "print(\"\\nðŸ“Š TensorBoard is running above. You can monitor:\")\n",
    "print(\"  - Mean reward per episode\")\n",
    "print(\"  - Value function loss\")\n",
    "print(\"  - Policy loss and entropy\")\n",
    "print(\"  - Individual reward components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "resume"
   },
   "source": [
    "## 6. Resume Training (Optional)\n",
    "\n",
    "If training was interrupted, you can resume from the latest checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "resume-code"
   },
   "outputs": [],
   "source": [
    "# Resume training from last checkpoint\n",
    "!python legged_gym/scripts/train_mujoco.py \\\n",
    "    --device cuda \\\n",
    "    --num_envs 512 \\\n",
    "    --resume \\\n",
    "    --load_run -1 \\\n",
    "    --checkpoint -1\n",
    "\n",
    "print(\"\\nâœ… Resumed training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 7. Download Trained Models\n",
    "\n",
    "Download the trained policy to test locally with Mujoco visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "import glob\n",
    "\n",
    "# Find the latest run directory\n",
    "log_dir = \"logs/g1_colab_training\"\n",
    "runs = sorted([d for d in os.listdir(log_dir) if os.path.isdir(os.path.join(log_dir, d))])\n",
    "\n",
    "if runs:\n",
    "    latest_run = runs[-1]\n",
    "    run_path = os.path.join(log_dir, latest_run)\n",
    "    \n",
    "    # Find all model checkpoints\n",
    "    models = sorted(glob.glob(os.path.join(run_path, \"model_*.pt\")))\n",
    "    \n",
    "    if models:\n",
    "        print(f\"Found {len(models)} model checkpoints in run: {latest_run}\\n\")\n",
    "        \n",
    "        # Download the latest model\n",
    "        latest_model = models[-1]\n",
    "        print(f\"Downloading: {latest_model}\")\n",
    "        files.download(latest_model)\n",
    "        \n",
    "        print(\"\\nâœ… Model downloaded!\")\n",
    "        print(\"\\nTo visualize locally:\")\n",
    "        print(\"  1. Install: pip install mujoco==3.2.3\")\n",
    "        print(\"  2. Clone repo: git clone https://github.com/julienokumu/unitree_rl_mugym.git\")\n",
    "        print(f\"  3. Copy downloaded model to: unitree_rl_mugym/logs/g1_colab_training/{latest_run}/\")\n",
    "        print(\"  4. Run: python deploy/deploy_mujoco/deploy_mujoco.py g1.yaml\")\n",
    "    else:\n",
    "        print(\"No model checkpoints found. Training may not have reached the first save interval.\")\n",
    "else:\n",
    "    print(\"No training runs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "compress"
   },
   "source": [
    "## 8. Create Checkpoint Archive (Optional)\n",
    "\n",
    "Create a zip file with all training checkpoints and logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "compress-code"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Find latest run\n",
    "log_dir = \"logs/g1_colab_training\"\n",
    "runs = sorted([d for d in os.listdir(log_dir) if os.path.isdir(os.path.join(log_dir, d))])\n",
    "\n",
    "if runs:\n",
    "    latest_run = runs[-1]\n",
    "    run_path = os.path.join(log_dir, latest_run)\n",
    "    \n",
    "    # Create zip archive\n",
    "    archive_name = f\"g1_training_{latest_run}\"\n",
    "    shutil.make_archive(archive_name, 'zip', run_path)\n",
    "    \n",
    "    print(f\"Created archive: {archive_name}.zip\")\n",
    "    print(f\"Size: {os.path.getsize(archive_name + '.zip') / 1024 / 1024:.2f} MB\\n\")\n",
    "    \n",
    "    # Download archive\n",
    "    files.download(f\"{archive_name}.zip\")\n",
    "    \n",
    "    print(\"\\nâœ… Archive downloaded!\")\n",
    "else:\n",
    "    print(\"No training runs found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "info"
   },
   "source": "---\n\n## Training Information\n\n### What the Robot Learns\n\nThe G1 humanoid robot learns to:\n- **Walk** in different directions (forward, backward, sideways)\n- **Turn** at various angular velocities\n- **Maintain balance** and upright posture\n- **Coordinate leg movements** for stable bipedal locomotion\n- **Follow velocity commands** (vx, vy, vyaw)\n\n### Reward Components\n\nThe policy is trained to maximize rewards for:\n- **Velocity tracking**: Following commanded velocities\n- **Survival**: Staying upright and alive\n- **Contact patterns**: Proper gait with alternating foot contact\n- **Smooth motion**: Minimal joint acceleration and action changes\n\nAnd minimize penalties for:\n- **Energy consumption**: High torques\n- **Undesired contacts**: Body parts touching the ground\n- **Joint limits**: Approaching position/velocity limits\n- **Orientation errors**: Tilting or falling\n\n### Network Architecture\n\n**Actor (Policy Network):**\n- Input: 47-dim observations (velocities, orientation, commands, joint states, phase)\n- LSTM: 47 â†’ 64 (temporal processing)\n- MLP: 64 â†’ 32 â†’ 12 actions (joint position targets)\n\n**Critic (Value Network):**\n- Input: 50-dim privileged observations (includes ground truth velocities)\n- LSTM: 50 â†’ 64 (temporal processing)\n- MLP: 64 â†’ 32 â†’ 1 value (state value estimate)\n\n### Hyperparameters\n\n- **Algorithm**: PPO (Proximal Policy Optimization)\n- **Environments**: 512 parallel simulations\n- **Steps per env**: 24 steps per rollout\n- **Max iterations**: 1000 (adjustable, ~35 hours total)\n- **Save interval**: 50 iterations (~2 hours)\n- **Learning rate**: 0.001\n- **Discount (Î³)**: 0.99\n- **GAE Î»**: 0.95\n- **Clip parameter**: 0.2\n- **Entropy coefficient**: 0.01\n\n### Training Time Estimates (T4 GPU)\n\n- **5 iterations**: ~10 minutes (quick test)\n- **50 iterations**: ~2 hours (perfect for Colab free tier)\n- **100 iterations**: ~3.5 hours (good progress)\n- **500 iterations**: ~17.5 hours (needs resume)\n- **1000 iterations**: ~35 hours (multiple sessions required)\n\n---\n\n## Troubleshooting\n\n**Training is slow:**\n- Make sure you selected GPU runtime (Runtime > Change runtime type > GPU)\n- T4 GPU gives ~98 steps/s, which is expected\n\n**Out of memory:**\n- Reduce `--num_envs` to 256 or 128\n- Restart runtime and try again\n\n**Session disconnected:**\n- Colab free tier has time limits (~12 hours)\n- Download checkpoints periodically\n- Resume training from last checkpoint when reconnected\n\n**Import errors:**\n- Re-run the dependency installation cell\n- Restart runtime if needed\n\n---\n\n## Repository\n\n**GitHub**: [julienokumu/unitree_rl_mugym](https://github.com/julienokumu/unitree_rl_mugym)\n\nBased on the original [unitreerobotics/unitree_rl_gym](https://github.com/unitreerobotics/unitree_rl_gym) with modifications for Mujoco compatibility and Google Colab support.\n\n---\n\n**Happy Training! ðŸ¤–ðŸš€**"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ GPU-Accelerated G1 Training with JAX/MJX on Google Colab\n",
    "\n",
    "**Train Unitree G1 humanoid robot 10-20x faster using JAX and MuJoCo MJX!**\n",
    "\n",
    "## What You'll Get\n",
    "- âš¡ **10-20x faster training** than CPU/PyTorch version\n",
    "- ðŸŽ® **1024-1536 parallel environments** on Colab T4 GPU\n",
    "- â±ï¸ **Train in ~1-2 hours** instead of 13+ hours\n",
    "- ðŸ’¾ **Automatic checkpointing** every 50 iterations\n",
    "- ðŸ“Š **TensorBoard monitoring** in real-time\n",
    "\n",
    "## Prerequisites\n",
    "- Google account (for Colab)\n",
    "- **GPU runtime enabled** (Runtime > Change runtime type > T4 GPU)\n",
    "\n",
    "## Estimated Time\n",
    "- Setup: ~5 minutes\n",
    "- Training (1000 iterations): ~1.5 hours on T4\n",
    "- Can stop anytime and resume from checkpoint\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verify GPU and Setup Environment\n",
    "\n",
    "**IMPORTANT:** Make sure you have **GPU runtime** enabled:\n",
    "1. Go to `Runtime` â†’ `Change runtime type`\n",
    "2. Select `T4 GPU` under Hardware accelerator\n",
    "3. Click `Save`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import os\n",
    "os.environ['JAX_DEFAULT_MATMUL_PRECISION'] = 'highest'  # For stability on T4\n",
    "\n",
    "print(\"\\nâœ“ GPU detected! Proceeding with installation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install JAX with CUDA Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install JAX with CUDA 12 (compatible with Colab T4)\n",
    "!pip install --upgrade \"jax[cuda12]>=0.4.23\" -q\n",
    "\n",
    "# Verify JAX installation\n",
    "import jax\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "\n",
    "if 'gpu' in str(jax.devices()[0]).lower():\n",
    "    print(\"\\nâœ“ JAX GPU successfully configured!\")\n",
    "else:\n",
    "    print(\"\\nâš  WARNING: GPU not detected by JAX. Check runtime settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/julienokumu/unitree_rl_mugym.git\n",
    "%cd unitree_rl_mugym\n",
    "\n",
    "# Install JAX/MJX dependencies\n",
    "!pip install -e .[jax_gpu] -q\n",
    "\n",
    "print(\"\\nâœ“ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run setup test\n",
    "!python test_jax_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Configure Training Parameters\n",
    "\n",
    "**T4 GPU Recommendations:**\n",
    "- `num_envs`: 1024-1536 (T4 has 16GB memory)\n",
    "- `num_timesteps`: 50M-100M\n",
    "- Expected speed: ~1000 iterations in 1.5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "ROBOT = \"g1\"\n",
    "NUM_ENVS = 1024  # Optimized for T4 GPU (16GB)\n",
    "NUM_TIMESTEPS = 50_000_000  # ~50M steps\n",
    "MAX_ITERATIONS = 1000  # Will run for ~1.5 hours\n",
    "SAVE_INTERVAL = 50  # Save every 50 iterations (~4.5 minutes)\n",
    "LEARNING_RATE = 3e-4\n",
    "EXPERIMENT_NAME = \"g1_jax_colab_t4\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Robot: {ROBOT}\")\n",
    "print(f\"  Parallel Envs: {NUM_ENVS}\")\n",
    "print(f\"  Max Iterations: {MAX_ITERATIONS}\")\n",
    "print(f\"  Expected Time: ~1.5 hours\")\n",
    "print(f\"  Checkpoint Interval: {SAVE_INTERVAL} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Start Training\n",
    "\n",
    "**Note:** This cell will run for ~1.5 hours. You can:\n",
    "- Stop it anytime (checkpoints saved every 50 iterations)\n",
    "- Monitor progress in TensorBoard (next cell)\n",
    "- Download checkpoints periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python legged_gym/scripts/train_jax_ppo.py \\\n",
    "  --robot {ROBOT} \\\n",
    "  --num_envs {NUM_ENVS} \\\n",
    "  --backend mjx \\\n",
    "  --num_timesteps {NUM_TIMESTEPS} \\\n",
    "  --learning_rate {LEARNING_RATE} \\\n",
    "  --experiment_name {EXPERIMENT_NAME} \\\n",
    "  --checkpoint_interval {SAVE_INTERVAL} \\\n",
    "  --log_interval 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Monitor Training with TensorBoard\n",
    "\n",
    "Run this in a separate cell while training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Find log directory\n",
    "import glob\n",
    "log_dirs = glob.glob('logs/g1_jax/*')\n",
    "if log_dirs:\n",
    "    latest_log = max(log_dirs, key=os.path.getctime)\n",
    "    print(f\"Monitoring: {latest_log}\")\n",
    "    %tensorboard --logdir {latest_log}\n",
    "else:\n",
    "    print(\"No log directories found yet. Start training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Download Trained Models\n",
    "\n",
    "Download checkpoints to visualize locally with MuJoCo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available checkpoints\n",
    "import glob\n",
    "import os\n",
    "\n",
    "checkpoint_dirs = glob.glob('logs/g1_jax/*')\n",
    "if checkpoint_dirs:\n",
    "    latest_run = max(checkpoint_dirs, key=os.path.getctime)\n",
    "    checkpoints = glob.glob(f'{latest_run}/*.pkl') + glob.glob(f'{latest_run}/*.pt')\n",
    "    \n",
    "    print(f\"Found {len(checkpoints)} checkpoints in {latest_run}\")\n",
    "    for ckpt in sorted(checkpoints)[-5:]:  # Show last 5\n",
    "        print(f\"  - {os.path.basename(ckpt)}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Train first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download checkpoint (change checkpoint name as needed)\n",
    "from google.colab import files\n",
    "\n",
    "# Get latest checkpoint\n",
    "checkpoint_dirs = glob.glob('logs/g1_jax/*')\n",
    "if checkpoint_dirs:\n",
    "    latest_run = max(checkpoint_dirs, key=os.path.getctime)\n",
    "    checkpoints = glob.glob(f'{latest_run}/*.pkl') + glob.glob(f'{latest_run}/*.pt')\n",
    "    \n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(f\"Downloading: {latest_checkpoint}\")\n",
    "        files.download(latest_checkpoint)\n",
    "        \n",
    "        # Also download config\n",
    "        config_path = f'{latest_run}/config.json'\n",
    "        if os.path.exists(config_path):\n",
    "            files.download(config_path)\n",
    "    else:\n",
    "        print(\"No checkpoints available yet\")\n",
    "else:\n",
    "    print(\"No training runs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Compress and Download All Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress entire training run for download\n",
    "import shutil\n",
    "\n",
    "checkpoint_dirs = glob.glob('logs/g1_jax/*')\n",
    "if checkpoint_dirs:\n",
    "    latest_run = max(checkpoint_dirs, key=os.path.getctime)\n",
    "    run_name = os.path.basename(latest_run)\n",
    "    \n",
    "    # Create zip archive\n",
    "    archive_name = f\"{run_name}_checkpoints\"\n",
    "    shutil.make_archive(archive_name, 'zip', latest_run)\n",
    "    \n",
    "    print(f\"Compressed {latest_run}\")\n",
    "    print(f\"Archive size: {os.path.getsize(archive_name + '.zip') / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    # Download\n",
    "    files.download(archive_name + '.zip')\n",
    "else:\n",
    "    print(\"No training runs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¬ Visualize Locally\n",
    "\n",
    "After downloading checkpoints, visualize on your local machine:\n",
    "\n",
    "```bash\n",
    "# Install MuJoCo locally\n",
    "pip install mujoco==3.2.3 torch pyyaml\n",
    "\n",
    "# Visualize trained policy\n",
    "python deploy/deploy_mujoco/deploy_mujoco.py g1.yaml \\\n",
    "    --policy /path/to/downloaded/checkpoint.pkl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Performance Comparison\n",
    "\n",
    "| Method | Num Envs | Time (1000 iter) | Speedup |\n",
    "|--------|----------|------------------|----------|\n",
    "| PyTorch CPU | 256 | ~13 hours | 1x |\n",
    "| JAX/MJX T4 | 1024 | ~1.5 hours | **8.7x** |\n",
    "\n",
    "## ðŸ’¡ Tips\n",
    "\n",
    "1. **Session Management**: Colab disconnects after ~12 hours\n",
    "   - Train in shorter sessions (1-2 hours)\n",
    "   - Download checkpoints frequently\n",
    "   - Resume from checkpoint in next session\n",
    "\n",
    "2. **Memory Issues**: If OOM errors occur:\n",
    "   - Reduce `NUM_ENVS` to 768 or 512\n",
    "   - Reduce network size in training script\n",
    "\n",
    "3. **Faster Training**: \n",
    "   - Use Colab Pro for A100 (40GB): ~4096 envs, 4x faster\n",
    "   - Or rent GPU from vast.ai, runpod.io\n",
    "\n",
    "## ðŸ› Troubleshooting\n",
    "\n",
    "**\"No GPU found\"**\n",
    "- Check Runtime > Change runtime type > T4 GPU\n",
    "- Restart runtime and run again\n",
    "\n",
    "**\"Out of Memory\"**\n",
    "- Reduce `NUM_ENVS` to 768\n",
    "- Restart runtime to clear memory\n",
    "\n",
    "**\"Training very slow\"**\n",
    "- First iteration takes 30-60s (JIT compilation)\n",
    "- Subsequent iterations should be fast (~5-10s)\n",
    "- If still slow, verify GPU is being used\n",
    "\n",
    "## ðŸ“š Resources\n",
    "\n",
    "- [Full Documentation](../docs/JAX_MJX_TRAINING.md)\n",
    "- [Quickstart Guide](../QUICKSTART_JAX.md)\n",
    "- [Repository](https://github.com/julienokumu/unitree_rl_mugym)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Training! ðŸ¤–**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

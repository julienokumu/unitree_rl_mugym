<div align="center">
  <h1 align="center">Unitree RL GYM</h1>
  <p align="center">
    <span> üåéEnglish </span> | <a href="README_zh.md"> üá®üá≥‰∏≠Êñá </a>
  </p>
</div>

<p align="center">
  <strong>Reinforcement learning for Unitree robots (Go2, H1, H1_2, G1) with Isaac Gym and Mujoco support.</strong>
</p>

<p align="center">
  ‚ú® <strong>Now with Google Colab training support - train without a local GPU!</strong> ‚ú®
</p>

<div align="center">

| <div align="center"> Isaac Gym </div> | <div align="center">  Mujoco </div> |  <div align="center"> Physical </div> |
|--- | --- | --- |
| [<img src="https://oss-global-cdn.unitree.com/static/32f06dc9dfe4452dac300dda45e86b34.GIF" width="240px">](https://oss-global-cdn.unitree.com/static/5bbc5ab1d551407080ca9d58d7bec1c8.mp4) | [<img src="https://oss-global-cdn.unitree.com/static/244cd5c4f823495fbfb67ef08f56aa33.GIF" width="240px">](https://oss-global-cdn.unitree.com/static/5aa48535ffd641e2932c0ba45c8e7854.mp4) | [<img src="https://oss-global-cdn.unitree.com/static/78c61459d3ab41448cfdb31f6a537e8b.GIF" width="240px">](https://oss-global-cdn.unitree.com/static/0818dcf7a6874b92997354d628adcacd.mp4) |

</div>

---

## üÜï What's New

### üöÄ **NEW**: GPU-Accelerated Training with JAX/MJX
- ‚ö° **8-10x Faster Training** - GPU-accelerated physics with MuJoCo MJX on Colab T4 (FREE!)
- üéÆ **1024+ Parallel Environments** - Train with 1024-8192 envs on a single GPU
- üî• **JAX-Powered** - JIT compilation and vectorization for maximum performance
- üìä **G1 Robot Ready** - Fully ported with phase-based gait control
- ‚è±Ô∏è **Train in 1.5 hours** - Instead of 13+ hours with CPU
- üÜì **Free on Colab T4** - No local GPU required
- üìì **[Ready-to-use Colab notebook](notebooks/train_g1_jax_colab.ipynb)** - Start training in one click!

### Existing Features: Mujoco-based Training
This fork also includes **PyTorch/Mujoco training for Google Colab**:

- ‚úÖ Train on Google Colab free tier (T4 GPU with PyTorch)
- ‚úÖ No Isaac Gym installation required for training
- ‚úÖ Visualize trained policies locally with Mujoco
- ‚úÖ Resume training across multiple Colab sessions
- ‚úÖ [PyTorch Colab notebook](notebooks/train_g1_mujoco_colab.ipynb) also available
- ‚úÖ Compatible with existing deployment tools

---

## üìñ Background

### Original Framework: Unitree RL Gym

This repository is based on [Unitree RL Gym](https://github.com/unitreerobotics/unitree_rl_gym), an excellent framework for training locomotion policies on Unitree robots using Isaac Gym.

**Original Features:**
- Isaac Gym-based training (4096 parallel environments on GPU)
- Supports Go2, H1, H1_2, G1 robots
- Sim2Real deployment
- Pre-trained models

**Limitations:**
- Requires local GPU with Isaac Gym
- Isaac Gym doesn't work on Google Colab
- Isaac Gym is legacy (superseded by Isaac Lab)

### Our Modification: Unitree RL MuGym

We've extended the framework with **Mujoco-based training environments** that:
- Run on Google Colab (no local GPU needed)
- Use Mujoco physics instead of Isaac Gym
- Support CPU training (slower but accessible)
- Maintain compatibility with the original deployment pipeline

**What's New:**
- **üöÄ JAX/MJX GPU Training**:
  - `MJXLeggedRobot` - GPU-accelerated JAX/MJX base environment (10-100x faster)
  - `MJXG1Robot` - G1 with phase-based gait, fully vectorized for GPU
  - `train_jax_ppo.py` - Brax PPO training with 2048-8192 parallel environments
  - Environment registry for easy robot instantiation
  - Complete documentation and test suite
- **PyTorch/CPU Training**:
  - `MujocoLeggedRobot` - Base Mujoco environment class with rsl_rl compatibility
  - `MujocoG1Robot` - G1-specific Mujoco implementation with phase-based gait
  - `train_mujoco.py` - Colab-compatible training script with robust config handling
  - `train_g1_mujoco_colab.ipynb` - Complete Colab notebook with step-by-step instructions
  - `ObservationDict` - Custom dict class supporting `.to(device)` for rsl_rl
  - Optional Isaac Gym imports - Framework works without Isaac Gym installed
  - Fallback math functions - Pure PyTorch implementations of Isaac Gym utilities

**Technical Improvements:**
- ‚úÖ XML model loading (URDF ‚Üí Mujoco XML with proper actuators)
- ‚úÖ Dictionary-based observations (policy/critic groups for rsl_rl)
- ‚úÖ Hybrid config structure (both nested and flat for rsl_rl compatibility)
- ‚úÖ Robust DOF detection (actuators ‚Üí joints ‚Üí config validation)
- ‚úÖ PD control mapping (automatic gain assignment from config)
- ‚úÖ Phase-based rewards (encouraging natural bipedal gait)

**What's Preserved:**
- Original Isaac Gym environments (still work if you have local GPU)
- Deployment scripts (Sim2Sim, Sim2Real)
- Configuration system and hyperparameters
- Reward functions and observation spaces
- Pre-trained models and checkpoint formats

---

## üöÄ Quick Start

### ‚ö° Option 1: GPU-Accelerated Training with JAX/MJX on Colab (Fastest - NEW!)

**8-10x faster than CPU training - FREE on Google Colab T4!**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/julienokumu/unitree_rl_mugym/blob/main/notebooks/train_g1_jax_colab.ipynb)

1. **Open Notebook**: Click badge above or upload `notebooks/train_g1_jax_colab.ipynb` to Colab
2. **Enable T4 GPU**: Runtime > Change runtime type > T4 GPU
3. **Run All Cells**: Training completes in ~1.5 hours (vs 13+ hours with CPU!)
4. **Download Model**: Checkpoints saved every 50 iterations

**Quick Links:**
- üìì [Colab Notebook](notebooks/train_g1_jax_colab.ipynb) - **Start here!**
- üìñ [Full JAX/MJX Documentation](docs/JAX_MJX_TRAINING.md)
- üöÄ [Quickstart Guide](QUICKSTART_JAX.md)

**Benefits:**
- Train in **1.5 hours** instead of 13 hours (on free T4 GPU)
- 1024 parallel environments (vs 256 with PyTorch/CPU)
- Full G1 humanoid support with phase-based gait
- No local GPU required - completely cloud-based
- Compatible with existing deployment tools

**Performance on Colab T4:**
- 1000 iterations: ~1.5 hours (vs ~13 hours PyTorch/CPU)
- Speedup: **8.7x faster**
- Memory usage: ~12GB (fits comfortably on T4)

---

### üê¢ Option 2: Train on Google Colab (CPU/GPU, No JAX required)

1. **Open Colab Notebook**
   - Upload `notebooks/train_g1_mujoco_colab.ipynb` to [Google Colab](https://colab.research.google.com/)
   - Or open directly: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/julienokumu/unitree_rl_mugym/blob/main/notebooks/train_g1_mujoco_colab.ipynb)

2. **Select GPU Runtime**
   - Go to `Runtime > Change runtime type > Hardware accelerator > GPU (T4)`
   - Free tier provides ~13 hours of training time

3. **Run All Cells**
   - Training takes ~13 hours for 10,000 iterations (can stop earlier)
   - Checkpoints saved every 500 iterations
   - TensorBoard available for real-time monitoring
   - Models automatically downloadable

4. **Visualize Locally**
   ```bash
   # Install on local machine
   pip install mujoco==3.2.3 torch pyyaml

   # Run visualization
   python deploy/deploy_mujoco/deploy_mujoco.py g1.yaml \
       --policy /path/to/downloaded/model.pt
   ```

### üíª Option 3: Train Locally with PyTorch/CPU (If You Have CPU/GPU)

```bash
# Clone repository
git clone https://github.com/julienokumu/unitree_rl_mugym.git
cd unitree_rl_mugym

# Install dependencies (Mujoco-only, no Isaac Gym)
pip install mujoco==3.2.3 scipy pyyaml tensorboard rsl-rl-lib torch
pip install -e .

# Train policy
python legged_gym/scripts/train_mujoco.py \
    --task g1_mujoco \
    --num_envs 256 \
    --max_iterations 10000 \
    --device cpu  # or 'cuda' if you have GPU

# Visualize
python deploy/deploy_mujoco/deploy_mujoco.py g1.yaml
```

---

## üìö Documentation

- **[COLAB_TRAINING.md](COLAB_TRAINING.md)** - Complete guide for Colab training workflow
- **[README_ORIGINAL.md](README_ORIGINAL.md)** - Original Unitree RL Gym documentation
- **[Notebooks](notebooks/)** - Jupyter notebooks for training

---

## ü§ñ Supported Robots

| Robot | Mujoco Support | Isaac Gym Support | DOF | Type |
|-------|---------------|-------------------|-----|------|
| **G1** | ‚úÖ Yes | ‚úÖ Yes | 12 | Humanoid |
| **H1** | üöß Coming Soon | ‚úÖ Yes | 12 | Humanoid |
| **H1_2** | üöß Coming Soon | ‚úÖ Yes | 12 | Humanoid |
| **Go2** | üöß Coming Soon | ‚úÖ Yes | 12 | Quadruped |

Currently, only **G1** has JAX/MJX support. Other robots can be added by following the implementation pattern.

---

## üì¶ Installation

### Option 1: Google Colab Training (No Local GPU Required)

1. **Open the Colab Notebook**: [train_g1_mujoco_colab.ipynb](notebooks/train_g1_mujoco_colab.ipynb)
2. **Enable GPU**: `Runtime > Change runtime type > GPU (T4)`
3. **Run all cells** - training takes ~2 hours per 50 iterations
4. **Download trained policy** and visualize locally

**Local visualization only** (no training):
```bash
pip install mujoco==3.2.3 torch pyyaml numpy
python deploy/deploy_mujoco/deploy_mujoco.py g1.yaml --policy /path/to/downloaded/policy_1.pt
```

### Option 2: Local Training (Isaac Gym)

For full Isaac Gym setup, see [setup.md](/doc/setup_en.md).

---

## üîÅ Workflow

`Train` ‚Üí `Play` ‚Üí `Sim2Sim` ‚Üí `Sim2Real`

- **Train**: Train policy in simulation (Isaac Gym or Mujoco)
- **Play**: Visualize and verify trained policy
- **Sim2Sim**: Test policy in different simulators
- **Sim2Real**: Deploy to physical robot

---

## üõ†Ô∏è Usage

### 1. Training

#### Mujoco Training (Colab/Local)
```bash
python legged_gym/scripts/train_mujoco.py --task=g1_mujoco
```

**Parameters:**
- `--device`: `cuda` or `cpu`
- `--num_envs`: Number of parallel environments (default: 512)
- `--max_iterations`: Training iterations (default: 1000)
- `--resume`: Resume from latest checkpoint

**Training tips:**
- 50-100 iterations: Basic coordination emerges (~2-4 hours on T4)
- 500 iterations: Stable walking policy (~20 hours, use resume)
- 1000+ iterations: Robust, efficient walking

#### Isaac Gym Training (Local Only)
```bash
python legged_gym/scripts/train.py --task=g1
```

**Parameters:**
- `--task`: Robot type (go2, g1, h1, h1_2)
- `--headless`: Run without GUI (faster)
- `--resume`: Resume training
- `--experiment_name`, `--run_name`: Organize experiments
- `--num_envs`: Parallel environments
- `--max_iterations`: Training iterations

**Models saved to**: `logs/<experiment_name>/<date_time>_<run_name>/model_<iteration>.pt`

---

### 2. Play (Visualization in Gym)

Visualize training results:
```bash
python legged_gym/scripts/play.py --task=g1
```

**Exports policy** to `logs/{experiment_name}/exported/policies/policy_1.pt` for deployment.

---

### 3. Sim2Sim (Mujoco)

Test policy in Mujoco simulator:
```bash
python deploy/deploy_mujoco/deploy_mujoco.py g1.yaml
```

**Custom policy:**
```bash
python deploy/deploy_mujoco/deploy_mujoco.py g1.yaml --policy /path/to/policy_1.pt
```

**Configuration:** Edit `deploy/deploy_mujoco/configs/g1.yaml` to customize policy path, control parameters, etc.

#### Mujoco Simulation Results

| G1 | H1 | H1_2 |
|--- | --- | --- |
| [![mujoco_g1](https://oss-global-cdn.unitree.com/static/244cd5c4f823495fbfb67ef08f56aa33.GIF)](https://oss-global-cdn.unitree.com/static/5aa48535ffd641e2932c0ba45c8e7854.mp4)  |  [![mujoco_h1](https://oss-global-cdn.unitree.com/static/7ab4e8392e794e01b975efa205ef491e.GIF)](https://oss-global-cdn.unitree.com/static/8934052becd84d08bc8c18c95849cf32.mp4)  |  [![mujoco_h1_2](https://oss-global-cdn.unitree.com/static/2905e2fe9b3340159d749d5e0bc95cc4.GIF)](https://oss-global-cdn.unitree.com/static/ee7ee85bd6d249989a905c55c7a9d305.mp4) |

---

### 4. Sim2Real (Physical Robot)

Deploy trained policy to physical robot (requires robot in debug mode):
```bash
python deploy/deploy_real/deploy_real.py {net_interface} {config_name}
```

**Parameters:**
- `net_interface`: Network interface name (e.g., `eth0`, `enp3s0`)
- `config_name`: Config file (e.g., `g1.yaml`, `h1.yaml`)

See [Physical Deployment Guide](deploy/deploy_real/README.md) for details.

#### Deployment Results

| G1 | H1 | H1_2 |
|--- | --- | --- |
| [![real_g1](https://oss-global-cdn.unitree.com/static/78c61459d3ab41448cfdb31f6a537e8b.GIF)](https://oss-global-cdn.unitree.com/static/0818dcf7a6874b92997354d628adcacd.mp4) | [![real_h1](https://oss-global-cdn.unitree.com/static/fa07b2fd2ad64bb08e6b624d39336245.GIF)](https://oss-global-cdn.unitree.com/static/ea0084038d384e3eaa73b961f33e6210.mp4) | [![real_h1_2](https://oss-global-cdn.unitree.com/static/a88915e3523546128a79520aa3e20979.GIF)](https://oss-global-cdn.unitree.com/static/12d041a7906e489fae79d55b091a63dd.mp4) |

---

## üéâ Acknowledgments

Built upon these excellent open-source projects:

- [legged_gym](https://github.com/leggedrobotics/legged_gym): Training framework
- [rsl_rl](https://github.com/leggedrobotics/rsl_rl.git): RL algorithms
- [mujoco](https://github.com/google-deepmind/mujoco.git): Physics simulation
- [unitree_sdk2_python](https://github.com/unitreerobotics/unitree_sdk2_python.git): Hardware interface
- [unitree_rl_gym](https://github.com/unitreerobotics/unitree_rl_gym): Original repository

---

## üîñ License

This project is licensed under the [BSD 3-Clause License](./LICENSE).

For details, please read the full [LICENSE file](./LICENSE).
